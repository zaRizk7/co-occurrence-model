# Probabilistic Models for Reasoning Object Co-Occurrences

## Abstract

Co-occurrence modeling is one of the classical statistical modeling problems that aims to understand relationships between entities based on their frequencies (i.e., topics by words or scenes by objects). A common way to model these co-occurrences is by building probabilistic/generative models for inference with quantifiable degrees of uncertainty. Many highly expressive probabilistic models are available to achieve this task. However, most are not intended for inference but rather for purely generating rich synthetic data. To properly understand these co-occurrences, we must use models that can be used for inference/reasoning (i.e., able to compute conditional probabilities) or have an interpretable representation. This project focuses on modeling object co-occurrences on COCO dataset, with probabilistic models usable for computing evidence queries. We explore multiple models to do such tasks, from simple mixture models, probabilistic graphical models (PGMs) like the Chow-Liu tree [10] and latent tree model (LTM) that have an interpretable structure, to more complex and expressive models including, Einsum networks (EiNet) and masked autoencoder for distribution estimation (MADE). Our evaluation consists of average negative log likelihood to see how well the model fits our data and leave-one-out log-loss to test how well our model can be used for inference tasks. Our results show that MADE performs best on all evaluation metrics. We also explore the interpretation of what these models have learned and experimented with mixtures and EiNets with random binary trees and BIN-G structures to see how well these tractable models scale in their performance.
